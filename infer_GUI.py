import streamlit as st
import io
from ultralytics import YOLO
import cv2
import numpy as np
from PIL import Image
import tempfile
import time
import os, sys

# é¡µé¢é…ç½®ï¼šæµè§ˆå™¨æ ‡ç­¾å’Œ favicon
st.set_page_config(
    page_title="è…¾å®‡æ‚¦ç›®æ ‡æ£€æµ‹",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------
# æ¨¡å‹é…ç½®
# ---------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATHS = {
    "Datachain_äº¤é€šç›®æ ‡è¯†åˆ«_light": os.path.join(BASE_DIR, "models", "datachain_light.pt"),
    "Datachain_äº¤é€šç›®æ ‡è¯†åˆ«_base":  os.path.join(BASE_DIR, "models", "datachain_o.pt"),
    "Datachain_äº¤é€šç›®æ ‡è¯†åˆ«_large": os.path.join(BASE_DIR, "models", "datachain_max.pt"),
    "Coco_é€šç”¨è¯†åˆ«_light":           os.path.join(BASE_DIR, "models", "yolo11n.pt"),
}

model_name = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹", list(MODEL_PATHS.keys()))
model = YOLO(MODEL_PATHS[model_name])

# ---------------------
# æ¨ç†å‡½æ•°
# ---------------------
def process_image(image: np.ndarray) -> np.ndarray:
    results = model(image)[0]
    for box in results.boxes:
        # è§£ææ¡†åæ ‡ã€ç½®ä¿¡åº¦ã€ç±»åˆ«
        r    = box.xyxy[0].cpu().numpy().astype(int)
        conf = float(box.conf)
        cls  = int(box.cls)
        label = f'{model.names[cls]} {conf:.2f}'
        # ç”»æ¡†å’Œæ ‡ç­¾
        cv2.rectangle(image, (r[0], r[1]), (r[2], r[3]), (255, 0, 0), 2)
        cv2.putText(image, label, (r[0], r[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
    return image

# ---------------------
# å‰ç«¯æ€»ä½“å¸ƒå±€
# ---------------------
st.title("äº¤é€šè§†é¢‘/å›¾åƒç›®æ ‡æ£€æµ‹ç³»ç»Ÿ")
st.markdown(
    "<div style='color: gray; font-size: 20px;'>æ¥æºï¼šç¬¬ä¸€å±Šâ€œæ•°æ®é“¾æ¯â€äººå·¥æ™ºèƒ½ç®—æ³•å¤§èµ› Â· è…¾å®‡æ‚¦å›¢é˜Ÿ</div>",
    unsafe_allow_html=True
)

st.markdown(
    "<div style='color: gray; font-size: 20px;'> </div>",
    unsafe_allow_html=True
)

option = st.sidebar.radio("è¾“å…¥ç±»å‹", ["Image", "Video"])

# ---------------------
# å›¾åƒè¯†åˆ«æ¨¡å—
# ---------------------
if option == "Image":
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾åƒ", type=['jpg', 'jpeg', 'png'])
    if uploaded_file is not None:
        # è¯»å–å¹¶å¤„ç†
        image     = Image.open(uploaded_file).convert("RGB")
        image_np  = np.array(image)
        processed = process_image(image_np.copy())
        st.image(processed, caption="è¯†åˆ«ç»“æœ", use_container_width=True)

        # ä¸‹è½½ç»“æœå›¾åƒ
        buf = io.BytesIO()
        Image.fromarray(processed).save(buf, format="PNG")
        buf.seek(0)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ç»“æœå›¾åƒ",
            data=buf,
            file_name="result.png",
            mime="image/png"
        )

# ---------------------
# è§†é¢‘è¯†åˆ«æ¨¡å—
# ---------------------
elif option == "Video":
    uploaded_video = st.file_uploader("ä¸Šä¼ è§†é¢‘", type=['mp4', 'avi', 'mov'])
    if uploaded_video is not None:
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_video.name)[1])
        tfile.write(uploaded_video.read())
        cap = cv2.VideoCapture(tfile.name)

        # å‡†å¤‡è¾“å‡ºè§†é¢‘
        output_path = os.path.join(os.path.dirname(tfile.name), "output.mp4")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        fps    = cap.get(cv2.CAP_PROP_FPS)
        size   = (int(cap.get(3)), int(cap.get(4)))
        out    = cv2.VideoWriter(output_path, fourcc, fps, size)

        stframe = st.empty()
        progress = st.progress(0)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        frame_idx = 0

        # é€å¸§æ¨ç†
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            processed = process_image(frame.copy())
            out.write(cv2.cvtColor(processed, cv2.COLOR_RGB2BGR))

            # å®æ—¶å±•ç¤ºä¸è¿›åº¦
            stframe.image(processed, channels="RGB", caption=f"å¸§: {frame_idx}", use_container_width=True)
            frame_idx += 1
            progress.progress(min(frame_idx / total_frames, 1.0))

        cap.release()
        out.release()

        st.success("è§†é¢‘è¯†åˆ«å®Œæˆï¼")

